# ğŸ“Š Entrega 5: RegresiÃ³n LogÃ­stica (RL)

---

## ğŸ§  Tema: PredicciÃ³n de Viviendas Caras

---

## ğŸ« Universidad del Valle de Guatemala - Campus Central  
**Facultad:** IngenierÃ­a  
**Departamento:** Ciencias de la ComputaciÃ³n  
**Curso:** MinerÃ­a de Datos (CC3074) - SecciÃ³n 10  
**Semestre:** II â€“ 2025  
**Proyecto:** Proyecto #2  
**Entrega:** Entrega 5 â€“ RegresiÃ³n LogÃ­stica  

---

## ğŸ‘¥ Integrantes del Grupo #1  
- **Pablo Daniel Barillas Moreno** - *CarnÃ© No. 22193*  
- **Mathew Cordero Aquino** - *CarnÃ© No. 22982*  
- **AndrÃ©s Rafael ChivalÃ¡n MarroquÃ­n** - *CarnÃ© No. 21534*

---

## ğŸ“Œ DescripciÃ³n del Proyecto  

Se trabajÃ³ con los datos del concurso **"House Prices: Advanced Regression Techniques"** de Kaggle. El objetivo de esta entrega fue construir un modelo de **regresiÃ³n logÃ­stica binaria** para predecir si una vivienda es **cara** en funciÃ³n de variables clave.

Este anÃ¡lisis se construyÃ³ sobre las entregas anteriores (Ãrboles de decisiÃ³n, Naive Bayes, KNN), utilizando los mismos conjuntos `train_set.csv` y `test_set.csv`.

---

## ğŸ” Actividades Realizadas  

### 1. CreaciÃ³n de variables dicotÃ³micas  
- Se transformÃ³ `SalePriceCat` (categÃ³rica: `barata`, `media`, `cara`) en 3 variables binarias:
  - `es_barata`
  - `es_media`
  - `es_cara`
- Estas variables permitieron modelar cada clase por separado.

### 2. ReutilizaciÃ³n de conjuntos  
- Se reutilizaron los conjuntos de entrenamiento y prueba generados en entregas anteriores.
- Se asegurÃ³ la reproducibilidad con semilla fija.

### 3. Modelo de regresiÃ³n logÃ­stica  
- Se entrenÃ³ un modelo para predecir `es_cara` (vivienda cara o no).
- Se usaron 5 predictores clave: `OverallQual`, `GrLivArea`, `GarageCars`, `TotalBsmtSF`, `YearBuilt`.
- ValidaciÃ³n cruzada de 10 folds, preprocesamiento (centrado, escalado, imputaciÃ³n) y upsampling.

### 4. AnÃ¡lisis del modelo  
- Se calculÃ³ el VIF para cada predictor â†’ **no hubo multicolinealidad** (todos los VIF < 2).
- Todos los coeficientes fueron estadÃ­sticamente significativos (`p < 0.01`).
- La matriz de correlaciÃ³n mostrÃ³ relaciones moderadas, sin colinealidades altas.
- Ajuste del modelo:
  - Accuracy (CV): 88.9%
  - AIC: 674.3
  - ReducciÃ³n sustancial de la devianza

### 5. EvaluaciÃ³n en conjunto de prueba  
- El modelo clasificÃ³ correctamente el **92.67%** de los casos.
- Matriz de confusiÃ³n:
  - `caro` predicho correctamente: 72
  - `no_caro` predicho correctamente: 143
- Kappa: 0.8385  
- Balanced Accuracy: 92.88%

### 6. Curvas de aprendizaje y sobreajuste  
- Se generaron curvas de error y precisiÃ³n para entrenamiento vs prueba.
- No se observÃ³ overfitting: las curvas convergen.
- El modelo generaliza correctamente y no depende excesivamente del conjunto de entrenamiento.

---

## ğŸ›  Herramientas Utilizadas  

- **Lenguaje:** R  
- **Entorno:** RStudio  
- **LibrerÃ­as:** `caret`, `dplyr`, `ggplot2`, `ROCR`, `car`  
- **Datos:** Kaggle House Prices (`train.csv`)  
- **Control de versiones:** GitHub  

---

## ğŸ“¢ Hallazgos Destacados  

âœ”ï¸ Todas las variables utilizadas en el modelo aportan significativamente a la predicciÃ³n.  
âœ”ï¸ El modelo no presenta multicolinealidad y se ajusta bien a los datos.  
âœ”ï¸ La clasificaciÃ³n en el conjunto de prueba tiene una alta precisiÃ³n (93%).  
âœ”ï¸ No se detectÃ³ sobreajuste segÃºn las curvas de aprendizaje.  
âœ”ï¸ El enfoque de clasificaciÃ³n binaria permitiÃ³ obtener un modelo simple y potente.
