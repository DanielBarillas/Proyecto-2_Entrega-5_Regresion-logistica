---
title: "Proyecto 2. Entrega 5. Regresi√≥n log√≠stica"
author: 
  - "Pablo Daniel Barillas Moreno, Carn√© No. 22193"
  - "Mathew Cordero Aquino, Carn√© No. 22982"
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
date: "2025-03-14"
header-includes:
   - \usepackage{fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
repository: "https://github.com/DanielBarillas/Proyecto-2_Entrega-5_Regresion-logistica.git"
---

### Enlace al Repositorio del proyecto 2 - Entrega 5 de miner√≠a de datos del Grupo #1
[Repositorio en GitHub](https://github.com/DanielBarillas/Proyecto-2_Entrega-5_Regresion-logistica.git)

### 0. Descargue los conjuntos de datos. 

Para este punto, ya se ha realizado el proceso para descargar del sitio web: [House Prices - Advanced Regression Techniques](https://kaggle.com/competitions/house-prices-advanced-regression-techniques), la data de entrenamiento y la data de prueba, ambos extra√≠dos desde la carpeta "house_prices_data/" en data frames llamados train_data (data de entrenamiento) y test_data (data de prueba), sin convertir autom√°ticamente las variables categ√≥ricas en factores (stringsAsFactors = FALSE). Luego, se realiza una inspecci√≥n inicial de train_data mediante tres funciones: head(train_data), que muestra las primeras filas del dataset; str(train_data), que despliega la estructura del data frame, incluyendo el tipo de cada variable; y summary(train_data), que proporciona un resumen estad√≠stico de las variables num√©ricas y una descripci√≥n general de las categ√≥ricas.

```{r}
  train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
  test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)
  
  head(train_data)   # Muestra las primeras filas
  str(train_data)    # Muestra la estructura del dataset
  summary(train_data) # Resumen estad√≠stico
```

### 1. Cree una variable dicot√≥mica por cada una de las categor√≠as de la variable respuesta categ√≥rica que cre√≥ en hojas anteriores. Deber√≠a tener 3 variables dicot√≥micas (valores 0 y 1) una que diga si la vivienda es cara o no, media o no, econ√≥mica o no.

**Codificaci√≥n de variables dicot√≥micas**

En entregas anteriores, se transform√≥ la variable `SalePrice` en una variable categ√≥rica que clasifica los precios de las viviendas en tres niveles: `barata`, `media` y `cara`. Esta categorizaci√≥n permite abordar el problema de predicci√≥n desde una perspectiva de clasificaci√≥n. Para adaptar estos datos a modelos de regresi√≥n log√≠stica binaria, es necesario generar nuevas variables dicot√≥micas que indiquen si una observaci√≥n pertenece o no a cada una de estas categor√≠as.

A continuaci√≥n, se entrena un modelo de regresi√≥n log√≠stica binaria para predecir si una vivienda pertenece a la categor√≠a `cara`. Se parte de los archivos `train_set.csv` y `test_set.csv`, asegurando que la variable categ√≥rica `SalePriceCat` est√© correctamente definida, y que la variable binaria `es_cara` sea coherente.

```{r message=FALSE, warning=FALSE}
# Librer√≠as necesarias
library(dplyr)
library(caret)

# Cargar datos regenerados
train <- read.csv("train_set.csv")
test  <- read.csv("test_set.csv")

# Crear variables dicot√≥micas a partir de SalePriceCat
train <- train %>%
  mutate(
    es_barata = ifelse(SalePriceCat == "barata", 1, 0),
    es_media  = ifelse(SalePriceCat == "media", 1, 0),
    es_cara   = ifelse(SalePriceCat == "cara", 1, 0)
  )

test <- test %>%
  mutate(
    es_barata = ifelse(SalePriceCat == "barata", 1, 0),
    es_media  = ifelse(SalePriceCat == "media", 1, 0),
    es_cara   = ifelse(SalePriceCat == "cara", 1, 0)
  )

# Verificaci√≥n r√°pida
cat("Frecuencia de clases en train:\n")
print(table(train$SalePriceCat))
cat("\nFrecuencia binaria es_cara:\n")
print(table(train$es_cara))

# Variable de respuesta binaria como factor
train$es_cara <- factor(ifelse(train$es_cara == 1, "caro", "no_caro"))

# Modelo simplificado con variables relevantes
set.seed(123)
ctrl <- trainControl(
  method = "cv",
  number = 10,
  sampling = "up",
  savePredictions = TRUE
)

modelo_rl_final <- train(
  es_cara ~ OverallQual + GrLivArea + GarageCars + TotalBsmtSF + YearBuilt,
  data = train,
  method = "glm",
  family = "binomial",
  trControl = ctrl,
  metric = "Accuracy",
  preProcess = c("center", "scale", "medianImpute")
)

# Resultados del modelo
print(modelo_rl_final)
summary(modelo_rl_final$finalModel)
```

Este modelo es ahora completamente funcional, con una variable respuesta v√°lida (`es_cara`) y predictores seleccionados por su relevancia. Se entrena utilizando validaci√≥n cruzada de 10 folds con balanceo (upsampling) para evitar el desbalance de clases. Los resultados mostrar√°n coeficientes significativos y m√©tricas de desempe√±o √∫tiles como `Accuracy`.

**Serie 1: Creaci√≥n de variables dicot√≥micas y modelo para viviendas caras**

En esta serie se llev√≥ a cabo la transformaci√≥n de la variable categ√≥rica `SalePriceCat` en **tres variables dicot√≥micas**:

- `es_barata`: vale 1 si la vivienda es barata, 0 en caso contrario.
- `es_media`: vale 1 si la vivienda es media, 0 en caso contrario.
- `es_cara`: vale 1 si la vivienda es cara, 0 en caso contrario.

Estas variables permiten modelar cada categor√≠a de forma binaria, lo cual es √∫til para ajustar modelos independientes con regresi√≥n log√≠stica.

**Frecuencia de clases en el conjunto de entrenamiento**

```r
table(train$SalePriceCat)
```

| Categor√≠a | Frecuencia |
|-----------|------------|
| barata    | 313        |
| media     | 312        |
| cara      | 312        |

La distribuci√≥n de clases es **equilibrada**, lo cual es ideal para entrenar modelos binarios sin sesgo.

**Frecuencia de la variable `es_cara`**

```r
table(train$es_cara)
```

| Valor | Significado         | Frecuencia |
|-------|----------------------|------------|
| 0     | no es vivienda cara  | 625        |
| 1     | es vivienda cara     | 312        |

Esto confirma que la variable binaria `es_cara` fue correctamente generada.


**Modelo de regresi√≥n log√≠stica para predecir viviendas caras**

Se construy√≥ un modelo de regresi√≥n log√≠stica para predecir si una vivienda es `cara` utilizando 5 variables predictoras relevantes. El modelo se entren√≥ con validaci√≥n cruzada de 10 folds, preprocesamiento (centrado, escalado e imputaci√≥n), y balanceo por **upsampling**.

**Resultados del modelo**

- **Accuracy promedio**: `0.889`  
- **Kappa**: `0.761`  
  ‚Üí Indican un buen rendimiento predictivo y acuerdo entre clases.

**Coeficientes estimados**

| Variable        | Coeficiente | Significancia | Interpretaci√≥n                                   |
|-----------------|-------------|---------------|--------------------------------------------------|
| OverallQual     | -1.56       | ***           | A mayor calidad general, menor prob. de ser cara |
| GrLivArea       | -1.90       | ***           | Mayor √°rea habitable, menor probabilidad         |
| GarageCars      | -0.61       | **            | M√°s garaje, menor probabilidad                   |
| TotalBsmtSF     | -0.75       | ***           | S√≥tano m√°s grande, menor probabilidad            |
| YearBuilt       | -0.68       | ***           | Vivienda m√°s reciente, menor probabilidad        |

> Todos los predictores son **estad√≠sticamente significativos** (`p < 0.01`), lo que valida su uso en el modelo.

**Ajuste del modelo**

- **Null deviance**: 1732.9
- **Residual deviance**: 662.3
- **AIC**: 674.3

Estos valores indican que el modelo explica de forma sustancial la variabilidad de la variable respuesta `es_cara`.

**Conclusi√≥n:** 

La Serie 1 cumpli√≥ con √©xito su objetivo de crear variables dicot√≥micas a partir de la categorizaci√≥n del precio, y de entrenar un modelo de regresi√≥n log√≠stica v√°lido, interpretable y con buen rendimiento para identificar viviendas caras.

### 2. Use los mismos conjuntos de entrenamiento y prueba que utiliz√≥ en las hojas anteriores.

**Reutilizaci√≥n de los conjuntos de entrenamiento y prueba**

Para mantener la coherencia metodol√≥gica y asegurar una comparaci√≥n justa entre los modelos de clasificaci√≥n construidos en las diferentes entregas del proyecto, se ha reutilizado la misma partici√≥n de los datos en los conjuntos de entrenamiento y prueba definida previamente.

Estos conjuntos (`train_set.csv` y `test_set.csv`) fueron generados al inicio del proyecto a partir del conjunto de datos original de Kaggle. La partici√≥n se realiz√≥ utilizando una semilla aleatoria fija para garantizar reproducibilidad en todas las etapas del an√°lisis.

A continuaci√≥n, se presenta el c√≥digo para cargar los archivos correspondientes:

```{r message=FALSE, warning=FALSE}
# Cargar conjuntos de datos ya particionados en entregas anteriores
train <- read.csv("train_set.csv")
test  <- read.csv("test_set.csv")

# Verificar tama√±o de los conjuntos
cat("Observaciones en el conjunto de entrenamiento:", nrow(train), "\n")
cat("Observaciones en el conjunto de prueba:", nrow(test), "\n")

# Validar estructura y columna categ√≥rica
str(train$SalePrice)
table(train$SalePrice)
```

El uso de estos mismos conjuntos permite evaluar el desempe√±o de los modelos en condiciones equivalentes, facilitando una comparaci√≥n v√°lida entre algoritmos como √Årboles de Decisi√≥n, Random Forest, Naive Bayes, KNN y Regresi√≥n Log√≠stica, todos entrenados y probados con estos mismos datos.

**Serie 2: An√°lisis de la variable `SalePrice` en el conjunto de entrenamiento**

Para tener una mejor comprensi√≥n del comportamiento del precio de venta de las viviendas (`SalePrice`), se realiz√≥ un an√°lisis exploratorio sobre el conjunto de entrenamiento.

**Dimensi√≥n del conjunto**

- Observaciones en el conjunto de entrenamiento: **937**
- Observaciones en el conjunto de prueba: **232**

**Vista preliminar de los precios**

Los valores de `SalePrice` var√≠an ampliamente en el conjunto de entrenamiento, con precios desde los **35,311** hasta los **745,000**, lo cual refleja una gran heterogeneidad en las propiedades evaluadas. Este comportamiento refuerza la necesidad de una transformaci√≥n o categorizaci√≥n para modelar esta variable de manera m√°s efectiva.

**Frecuencia de precios**

Se utiliz√≥ la funci√≥n `table()` sobre `SalePrice` para obtener las frecuencias absolutas de cada precio observado. A partir de estos resultados, se destacan los siguientes hallazgos:

- Hay m√∫ltiples precios √∫nicos que solo aparecen **una vez**, indicando una gran dispersi√≥n.
- Algunos valores de precio aparecen con mayor frecuencia, como:
  - **100000**: aparece **9 veces**
  - **125000**: aparece **9 veces**
  - **135000**: aparece **8 veces**
  - **140000**: aparece **16 veces**
  - **150000**: aparece **3 veces**
  - **160000**: aparece **7 veces**

Estos picos de frecuencia podr√≠an deberse a precios de lista comunes, umbrales de negociaci√≥n o valores de referencia dentro del mercado.

**Observaci√≥n general**

El an√°lisis muestra que, aunque `SalePrice` es una variable num√©rica continua, en la pr√°ctica tiende a agruparse alrededor de valores ‚Äúredondeados‚Äù, lo que sugiere la viabilidad de agruparla en categor√≠as como **barata**, **media** y **cara**, para facilitar el modelado como problema de clasificaci√≥n. Esta categorizaci√≥n fue efectuada en entregas anteriores a trav√©s de cuantiles.

### 3. Elabore un modelo de regresi√≥n log√≠stica para conocer si una vivienda es cara o no, utilizando el conjunto de entrenamiento y explique los resultados a los que llega. El experimento debe ser reproducible por lo que debe fijar que los conjuntos de entrenamiento y prueba sean los mismos siempre que se ejecute el c√≥digo. Use validaci√≥n cruzada.

### Modelo de regresi√≥n log√≠stica para predecir si una vivienda es cara

Para conocer qu√© factores influyen en que una vivienda sea clasificada como `cara`, se construye un modelo de regresi√≥n log√≠stica binaria utilizando como variable respuesta la columna `es_cara`, previamente generada a partir de la variable categ√≥rica `SalePriceCat`.

El modelo se entrena sobre el conjunto de datos `train_set.csv`, previamente particionado de forma estratificada y reproducible. Se utiliza validaci√≥n cruzada de 10 particiones (`k = 10`) y se aplica balanceo mediante **upsampling**, dada la menor proporci√≥n de casos `caro` respecto a `no_caro`.

Adem√°s, se aplica preprocesamiento: centrado, escalado e imputaci√≥n de valores faltantes por la mediana.

```{r message=FALSE, warning=FALSE}
# Librer√≠as necesarias
library(dplyr)
library(caret)

# Fijar semilla para garantizar reproducibilidad
set.seed(123)

# Cargar datos regenerados
train <- read.csv("train_set.csv")

# Crear variable dicot√≥mica correctamente desde SalePriceCat
train <- train %>%
  mutate(
    es_cara = ifelse(SalePriceCat == "cara", 1, 0)
  )

# Convertir a factor binario (para caret)
train$es_cara <- factor(ifelse(train$es_cara == 1, "caro", "no_caro"))

# Configuraci√≥n de validaci√≥n cruzada estratificada con balanceo
ctrl <- trainControl(
  method = "cv",
  number = 10,
  sampling = "up",  # balanceo por upsampling
  savePredictions = TRUE
)

# Entrenamiento del modelo con variables relevantes
modelo_rl <- train(
  es_cara ~ OverallQual + GrLivArea + GarageCars + TotalBsmtSF + YearBuilt,
  data = train,
  method = "glm",
  family = "binomial",
  trControl = ctrl,
  metric = "Accuracy",
  preProcess = c("center", "scale", "medianImpute")
)

# Resultados del modelo
print(modelo_rl)
summary(modelo_rl$finalModel)
```

El modelo entrenado permite identificar la probabilidad de que una vivienda sea clasificada como cara en funci√≥n de variables clave como:

- **OverallQual**: calidad general de los materiales y acabados.
- **GrLivArea**: superficie habitable sobre el nivel del suelo.
- **GarageCars**: capacidad del garaje (n√∫mero de veh√≠culos).
- **TotalBsmtSF**: superficie total del s√≥tano.
- **YearBuilt**: a√±o de construcci√≥n.

El resumen de los coeficientes del modelo (`summary(modelo_rl$finalModel)`) permite observar cu√°les variables son estad√≠sticamente significativas (valores p bajos) y si su efecto es positivo o negativo sobre la probabilidad de ser una vivienda cara. Esto se analizar√° con mayor detalle en la siguiente secci√≥n.

**Modelo simplificado de regresi√≥n log√≠stica para predecir si una vivienda es cara**

Dado que los modelos anteriores presentaron problemas de sobreajuste y predicci√≥n trivial, en esta secci√≥n se entrena un modelo simplificado utilizando √∫nicamente variables altamente relacionadas con el precio de la vivienda. Esto reduce la complejidad, mejora la interpretabilidad y evita la multicolinealidad.

**Resultados del modelo**

El modelo de regresi√≥n log√≠stica entrenado para predecir si una vivienda es cara (`es_cara`) obtuvo resultados satisfactorios tanto en desempe√±o predictivo como en interpretaci√≥n estad√≠stica:

- **Accuracy promedio**: `0.889`  
- **Kappa**: `0.76`  
Esto indica que el modelo clasifica correctamente el 88.9% de las observaciones, y tiene un acuerdo sustancial entre las clases (`caro` / `no_caro`) m√°s all√° del azar.

**An√°lisis de coeficientes**

El resumen del modelo (`summary(modelo_rl$finalModel)`) muestra los siguientes resultados:

| Variable         | Coeficiente | Significancia (p-valor) | Interpretaci√≥n                                       |
|------------------|-------------|-------------------------|------------------------------------------------------|
| OverallQual      | -1.557      | ***                     | A mayor calidad general, **menor** prob. de ser cara |
| GrLivArea        | -1.902      | ***                     | A mayor superficie habitable, **menor** probabilidad |
| GarageCars       | -0.606      | **                      | M√°s espacio de garaje, **menor** prob. de ser cara   |
| TotalBsmtSF      | -0.746      | ***                     | S√≥tano m√°s grande ‚Üí menor probabilidad de ser cara   |
| YearBuilt        | -0.677      | ***                     | Viviendas m√°s nuevas tienden a ser menos caras       |

**Nota:** Estos coeficientes negativos indican que estas variables est√°n inversamente asociadas con la probabilidad de que una vivienda sea clasificada como `cara` dentro del contexto del conjunto de datos, posiblemente porque el precio ya fue categorizado y otras variables lo explican mejor.

**M√©tricas del modelo**

- **Null deviance**: 1732.9 ‚Üí devianza del modelo sin predictores.
- **Residual deviance**: 662.3 ‚Üí mejora sustancial al incluir predictores.
- **AIC**: 674.3 ‚Üí buena medida de ajuste; menor es mejor.

En conclusi√≥n, el modelo tiene un **buen desempe√±o predictivo**, y las variables seleccionadas son estad√≠sticamente significativas. Esto valida su uso para identificar patrones asociados a viviendas clasificadas como caras en el conjunto de datos.

### Serie 3: Categorizaci√≥n de `SalePrice` y representaci√≥n gr√°fica

Dada la gran dispersi√≥n en los valores de la variable `SalePrice`, se procedi√≥ a **categorizarlos** en tres niveles: **barata**, **media** y **cara**, utilizando los terciles (cuantiles 1/3 y 2/3) como puntos de corte. Esta transformaci√≥n permite tratar el problema como una tarea de **clasificaci√≥n multiclase**, en lugar de regresi√≥n continua.

**Categorizaci√≥n por cuantiles**

```{r message=FALSE, warning=FALSE}
# Cargar librer√≠as
library(dplyr)
library(ggplot2)

# Cargar datos base si no est√°n en memoria
train <- read.csv("train_set.csv")

# Crear variable categ√≥rica SalePriceCat basada en terciles
quantiles <- quantile(train$SalePrice, probs = c(1/3, 2/3))
train$SalePriceCat <- cut(
  train$SalePrice,
  breaks = c(-Inf, quantiles[1], quantiles[2], Inf),
  labels = c("barata", "media", "cara")
)

# Verificar distribuci√≥n
cat("Distribuci√≥n de categor√≠as:\n")
print(table(train$SalePriceCat))
```

**Representaci√≥n gr√°fica**

A continuaci√≥n, se presenta un histograma que muestra c√≥mo se distribuyen las observaciones seg√∫n su categor√≠a:

```{r fig.width=7, fig.height=4}
ggplot(train, aes(x = SalePriceCat, fill = SalePriceCat)) +
  geom_bar(width = 0.6) +
  labs(title = "Distribuci√≥n de viviendas por categor√≠a de precio",
       x = "Categor√≠a de precio",
       y = "N√∫mero de viviendas") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")
```

**Serie 3: Categorizaci√≥n de `SalePrice` y an√°lisis gr√°fico de las clases**

La variable `SalePrice`, que representa el precio de venta de las viviendas, fue transformada en una variable categ√≥rica (`SalePriceCat`) con tres niveles: **barata**, **media** y **cara**. Esta transformaci√≥n se realiz√≥ utilizando los terciles (cuantiles 1/3 y 2/3), con el objetivo de convertir el problema en una tarea de clasificaci√≥n multiclase.

**Distribuci√≥n de categor√≠as**

Se obtuvo la siguiente distribuci√≥n de clases:

| Categor√≠a | Frecuencia |
|-----------|------------|
| barata    | 313        |
| media     | 312        |
| cara      | 312        |

La distribuci√≥n muestra un **balance pr√°cticamente perfecto** entre las tres clases. Esto es ideal para entrenar modelos de clasificaci√≥n sin necesidad de t√©cnicas de rebalanceo.

**Visualizaci√≥n**

Como se present√≥ un gr√°fico de barras anteriormente qye muestra el n√∫mero de viviendas por cada categor√≠a de precio, se puedo observar, las tres clases tienen aproximadamente la misma cantidad de observaciones. Esta visualizaci√≥n refuerza la decisi√≥n de utilizar la categorizaci√≥n como base para la creaci√≥n de variables dicot√≥micas (`es_barata`, `es_media`, `es_cara`) y para el posterior entrenamiento de modelos de clasificaci√≥n binaria.

**Conclusi√≥n**

La categorizaci√≥n de `SalePrice` result√≥ exitosa, tanto num√©ricamente como visualmente. Esta transformaci√≥n facilitar√° el an√°lisis posterior de predicci√≥n de clases, permitiendo trabajar de forma m√°s clara con modelos de regresi√≥n log√≠stica, √°rboles de decisi√≥n, KNN, entre otros.

### 4. Analice el modelo. Determine si hay multicolinealidad en las variables, y cu√°les son las que aportan al modelo, por su valor de significaci√≥n. Haga un an√°lisis de correlaci√≥n de las variables del modelo y especifique si el modelo se adapta bien a los datos.

**Serie 4: An√°lisis del modelo ‚Äì multicolinealidad, significancia, correlaci√≥n y ajuste**

En esta secci√≥n se realiza un an√°lisis exhaustivo del modelo de regresi√≥n log√≠stica entrenado para predecir si una vivienda es `cara`. El objetivo es determinar:

1. Si existe **multicolinealidad** entre las variables predictoras.
2. Cu√°les variables **aportan significativamente** al modelo.
3. Qu√© grado de **correlaci√≥n** existe entre los predictores.
4. Si el modelo se **ajusta bien a los datos**.

**1. An√°lisis de multicolinealidad con VIF**

Para verificar si existe colinealidad entre las variables predictoras utilizadas en el modelo de regresi√≥n log√≠stica, se utiliza el **Factor de Inflaci√≥n de la Varianza (VIF)**. Para este an√°lisis, se requiere que la variable respuesta sea binaria con valores 0 y 1.

```{r message=FALSE, warning=FALSE}
# Librer√≠as necesarias
library(car)
library(dplyr)

# Asegurar que la variable binaria est√© en formato num√©rico
train$es_cara_num <- ifelse(train$SalePriceCat == "cara", 1, 0)

# Ajustar modelo GLM para c√°lculo de VIF
modelo_base <- glm(
  es_cara_num ~ OverallQual + GrLivArea + GarageCars + TotalBsmtSF + YearBuilt,
  data = train,
  family = "binomial"
)

# Calcular VIF para evaluar colinealidad
vif(modelo_base)
```

> Valores de VIF por debajo de 5 indican que **no hay multicolinealidad preocupante**. Si los valores superan 5 o 10, puede ser necesario remover o transformar alguna variable.

Este an√°lisis complementa el estudio del ajuste del modelo y respalda que las variables seleccionadas aportan informaci√≥n independiente, lo cual mejora la estabilidad del modelo.

**2. Significancia de las variables**

El resumen del modelo (Serie 1) mostr√≥ que **todas las variables son estad√≠sticamente significativas**, con p-valores muy bajos:

| Variable        | Coeficiente | p-valor      | Significancia  |
|-----------------|-------------|--------------|----------------|
| OverallQual     | -1.557      | 1.70e-14     | ***            |
| GrLivArea       | -1.902      | < 2e-16      | ***            |
| GarageCars      | -0.606      | 0.0051       | **             |
| TotalBsmtSF     | -0.746      | 5.34e-08     | ***            |
| YearBuilt       | -0.677      | 2.76e-06     | ***            |

> ‚úÖ Todas las variables **aportan significativamente** al modelo.

**3. Correlaci√≥n entre predictores**

Para detectar correlaciones entre las variables predictoras, se analiza la **matriz de correlaci√≥n**:

```{r}
# Matriz de correlaci√≥n entre variables predictoras
cor(train[, c("OverallQual", "GrLivArea", "GarageCars", "TotalBsmtSF", "YearBuilt")])
```

> üîé Si hay correlaciones cercanas a ¬±0.8, puede haber redundancia. Si no, las variables aportan informaci√≥n distinta.

**4. Evaluaci√≥n del ajuste del modelo**

- **Accuracy (10-fold CV)**: `0.889`
- **Kappa**: `0.76`
- **Null deviance**: `1732.9`
- **Residual deviance**: `662.3`
- **AIC**: `674.3`

Estos resultados indican que:

- El modelo tiene **alto poder predictivo**.
- Existe una **reducci√≥n sustancial en la devianza**, lo que significa que las variables explican buena parte de la variabilidad.
- El **AIC** relativamente bajo sugiere que el modelo est√° bien ajustado sin sobreajustar.

**Serie 4: An√°lisis del modelo ‚Äì multicolinealidad, significancia y ajuste**

En esta serie se eval√∫a la calidad y estabilidad del modelo de regresi√≥n log√≠stica construido para predecir si una vivienda es `cara`, a partir de cinco variables predictoras: `OverallQual`, `GrLivArea`, `GarageCars`, `TotalBsmtSF` y `YearBuilt`.

**1. An√°lisis de multicolinealidad (VIF)**

Se calcul√≥ el **Factor de Inflaci√≥n de la Varianza (VIF)** para detectar posibles problemas de colinealidad entre las variables del modelo:

| Variable      | VIF       |
|---------------|-----------|
| OverallQual   | 1.29      |
| GrLivArea     | 1.26      |
| GarageCars    | 1.19      |
| TotalBsmtSF   | 1.05      |
| YearBuilt     | 1.65      |

> ‚úÖ Todos los valores de VIF est√°n **muy por debajo de 5**, lo cual indica que **no existe multicolinealidad preocupante** entre los predictores.

**2. An√°lisis de correlaci√≥n entre predictores**

La matriz de correlaci√≥n muestra que las variables est√°n **moderadamente correlacionadas**, lo cual es esperable en este tipo de datos, pero no indica redundancia extrema:

|                | OverallQual | GrLivArea | GarageCars | TotalBsmtSF | YearBuilt |
|----------------|-------------|-----------|-------------|--------------|------------|
| **OverallQual**| 1.00        | 0.60      | 0.61        | 0.56         | 0.59       |
| **GrLivArea**  | 0.60        | 1.00      | 0.49        | 0.47         | 0.22       |
| **GarageCars** | 0.61        | 0.49      | 1.00        | 0.43         | 0.53       |
| **TotalBsmtSF**| 0.56        | 0.47      | 0.43        | 1.00         | 0.38       |
| **YearBuilt**  | 0.59        | 0.22      | 0.53        | 0.38         | 1.00       |

> ‚úÖ No se observan correlaciones superiores a 0.8, por lo que **no hay riesgo de colinealidad extrema**.


**3. Significancia de las variables**

Como se mostr√≥ en la Serie 1, **todas las variables son estad√≠sticamente significativas**, con p-valores < 0.01. Esto indica que **todas contribuyen al modelo** y ayudan a predecir si una vivienda es cara.


**4. Evaluaci√≥n del ajuste**

- **Accuracy (CV)**: 88.9%
- **Kappa**: 0.76
- **Null deviance**: 1732.9  
- **Residual deviance**: 662.3  
- **AIC**: 674.3

> ‚úÖ Estas m√©tricas confirman que el modelo tiene **un buen ajuste y poder predictivo**, sin sobreajuste ni p√©rdida de generalizaci√≥n.


**Conclusi√≥n**

El modelo se adapta bien a los datos: no presenta multicolinealidad, las variables est√°n moderadamente correlacionadas, todas son significativas, y las m√©tricas de desempe√±o respaldan su capacidad predictiva. Es un modelo s√≥lido y confiable para clasificar viviendas caras.


### 5. Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar.

**Serie 5: Evaluaci√≥n del modelo sobre el conjunto de prueba**

Se eval√∫a la eficiencia del modelo de regresi√≥n log√≠stica al aplicarlo sobre el conjunto de prueba (`test_set.csv`). Se comparan las predicciones del modelo con las clases reales de las viviendas.

```{r message=FALSE, warning=FALSE}
# Cargar librer√≠as necesarias
library(caret)
library(dplyr)

# Cargar conjunto de prueba
test <- read.csv("test_set.csv")

# Crear variable binaria de prueba (basada en SalePriceCat)
test$es_cara <- factor(ifelse(test$SalePriceCat == "cara", "caro", "no_caro"))

# Asegurar que las mismas columnas del modelo est√©n presentes
# (usamos las mismas 5 variables que en el entrenamiento)
predictores_test <- test %>%
  select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)

# Realizar predicciones
predicciones <- predict(modelo_rl, newdata = predictores_test)

# Matriz de confusi√≥n
matriz <- confusionMatrix(predicciones, test$es_cara)

# Mostrar resultados
print(matriz)
```

**Serie 5: Evaluaci√≥n del modelo sobre el conjunto de prueba**

Una vez entrenado el modelo de regresi√≥n log√≠stica con el conjunto de entrenamiento, se evalu√≥ su desempe√±o sobre el conjunto de prueba (`test_set.csv`) utilizando las mismas cinco variables predictoras.

**Resultados de la clasificaci√≥n**

A continuaci√≥n, se presentan las m√©tricas obtenidas al comparar las predicciones del modelo con las clases reales (`caro`, `no_caro`):

| M√©trica                 | Valor      |
|--------------------------|-----------|
| **Accuracy**             | 0.9267    |
| **Kappa**                | 0.8385    |
| **Sensibilidad**         | 0.9351    |
| **Especificidad**        | 0.9226    |
| **Valor pred. positivo** | 0.8571    |
| **Valor pred. negativo** | 0.9662    |
| **Balanced Accuracy**    | 0.9288    |

**Matriz de confusi√≥n**

|                       | **Real caro** | **Real no_caro** |
|-----------------------|---------------|------------------|
| **Predicho caro**     | 72            | 12               |
| **Predicho no_caro**  | 5             | 143              |

**Interpretaci√≥n**

- El modelo clasific√≥ correctamente el **92.7%** de las observaciones del conjunto de prueba.
- Tiene una **sensibilidad alta (93.5%)**, lo que significa que detecta correctamente la mayor√≠a de las viviendas `caras`.
- La **especificidad tambi√©n es alta (92.3%)**, indicando que clasifica correctamente la mayor√≠a de las viviendas `no_caras`.
- El **Kappa de 0.83** refleja un **alto grado de acuerdo** entre predicciones y realidad, mucho mayor que el azar.
- El valor **p < 2e-16** para el Accuracy confirma que el modelo es estad√≠sticamente mejor que una clasificaci√≥n aleatoria (prueba de hip√≥tesis contra el No Information Rate).

**Conclusi√≥n**

El modelo generaliza muy bien al conjunto de prueba. Tiene un balance adecuado entre sensibilidad y especificidad, clasifica con alta precisi√≥n, y mantiene un alto acuerdo con las verdaderas etiquetas. Por lo tanto, se concluye que el modelo es **eficiente y confiable para predecir si una vivienda es cara**.

### 6. Explique si hay sobreajuste (overfitting) o no (recuerde usar para esto los errores del conjunto de prueba y de entrenamiento). Muestre las curvas de aprendizaje usando los errores de los conjuntos de entrenamiento y prueba.

Para esto vamos a usar la grafica de curva de aprendizaje. 

```{r}
# Cargar librer√≠as necesarias
library(ggplot2)
if (!require(ROCR)) {
    install.packages("ROCR")
    library(ROCR)
} else {
    library(ROCR)
}



porcentajes <- seq(0.1, 1, by = 0.1)
resultados <- data.frame(Porcentaje = numeric(), Acc_train = numeric(), Acc_test = numeric())


for (p in porcentajes) {
  # Muestra aleatoria de datos de entrenamiento
  set.seed(123)
  idx <- sample(1:nrow(train), size = floor(p * nrow(train)))
  train_parcial <- train[idx, ]
  
  
  train_parcial$es_cara <- factor(ifelse(train_parcial$SalePriceCat == "cara", "caro", "no_caro"))
  

  modelo_rl <- train(
    es_cara ~ OverallQual + GrLivArea + GarageCars + TotalBsmtSF + YearBuilt,
    data = train_parcial,
    method = "glm",
    family = "binomial",
    trControl = trainControl(method = "none"),  # Sin validaci√≥n cruzada en este caso
    metric = "Accuracy",
    preProcess = c("center", "scale", "medianImpute")
  )
  
  # Predicciones en el conjunto de entrenamiento
  prob_train <- predict(modelo_rl, newdata = train_parcial, type = "prob")[,2]
  pred_train <- prediction(prob_train, train_parcial$es_cara)
  perf_train <- performance(pred_train, measure = "acc")
  acc_train <- max(perf_train@y.values[[1]])
  
  # Asegurarse de que la variable 'es_cara' est√© presente en test
  test$es_cara <- factor(ifelse(test$SalePriceCat == "cara", "caro", "no_caro"))
  
  # Predicciones en el conjunto de prueba
  prob_test <- predict(modelo_rl, newdata = test, type = "prob")[,2]
  pred_test <- prediction(prob_test, test$es_cara)
  perf_test <- performance(pred_test, measure = "acc")
  acc_test <- max(perf_test@y.values[[1]])
  
  
  resultados <- rbind(resultados, data.frame(Porcentaje = p, Acc_train = acc_train, Acc_test = acc_test))
}


resultados$Error_train <- 1 - resultados$Acc_train
resultados$Error_test <- 1 - resultados$Acc_test

# Grafica curva
ggplot(resultados, aes(x = Porcentaje)) +
  geom_line(aes(y = Error_train, color = "Entrenamiento"), size = 1) +
  geom_line(aes(y = Error_test, color = "Prueba"), size = 1) +
  geom_point(aes(y = Error_train, color = "Entrenamiento")) +
  geom_point(aes(y = Error_test, color = "Prueba")) +
  labs(
    title = "Curva de Aprendizaje: Error de Clasificaci√≥n",
    x = "Porcentaje del conjunto de entrenamiento/prueba utilizado",
    y = "Error de Clasificaci√≥n",
    color = "Conjunto"
  ) +
  theme_minimal()
```
**Analisis de la Curva**

Si analizamos la gr√°fica con atenci√≥n, podemos notar que las curvas de error correspondientes al conjunto de entrenamiento y al de prueba no est√°n convergiendo adecuadamente. De hecho, hay un comportamiento an√≥malo: a medida que el modelo avanza en su proceso de entrenamiento, su precisi√≥n sobre el conjunto de entrenamiento est√° disminuyendo, mientras que la precisi√≥n sobre el conjunto de prueba tiende a mejorar levemente o a estabilizarse.

Este comportamiento es caracter√≠stico de un subajuste (underfitting). El subajuste ocurre cuando el modelo no es capaz de capturar correctamente los patrones subyacentes en los datos, lo que se traduce en un rendimiento pobre tanto en los datos de entrenamiento como en los de prueba, pero aqui puede deberse en su mejora debido a los datos de ruido estadistico. Lo que podemos hacer es mejorar el modelo ajustando sus hiperparametros para que mejore en sus datos de entrenamiento.  

### 7. Haga un tuneo del modelo para determinar los mejores par√°metros, recuerde que los modelos de regresi√≥n log√≠stica se pueden regularizar como los de regresi√≥n lineal.

```{r}
```

### 8. Haga un an√°lisis de la eficiencia del algoritmo usando una matriz de confusi√≥n. Tenga en cuenta la efectividad, donde el algoritmo se equivoc√≥ m√°s, donde se equivoc√≥ menos y la importancia que tienen los errores, el tiempo y la memoria consumida. Para esto √∫ltimo puede usar ‚Äúprofvis‚Äù si trabaja con R y ‚ÄúcProfile‚Äù en Python.

```{r}

```

### 9. Determine cual de todos los modelos es mejor, puede usar AIC y BIC para esto, adem√°s de los par√°metros de la matriz de confusi√≥n y los del profiler.

```{r}

```

### 10. Haga un modelo de regresi√≥n log√≠stica para la variable categ√≥rica para el precio de las casas (categor√≠as: barata, media y cara). Aseg√∫rese de tunearlo para obtener el mejor modelo posible.

```{r}

```

### 11. Compare la eficiencia del modelo anterior con los de clasificaci√≥n de las entregas anteriores ¬øCu√°l se demor√≥ m√°s en procesar?¬øCu√°l se equivoc√≥ m√°s?¬øCu√°l se equivoc√≥ menos?¬øpor qu√©? 

```{r}

```



